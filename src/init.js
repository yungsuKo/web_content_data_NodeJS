import "dotenv/config";
import "./db";
import app from "./server";
import AccountUrl from "./models/AccountUrl";
import CrawlUrlPost from "./models/CrawlUrlPost";
import PostDetail from "./models/PostDetail";
import schedulePostCrawler from "./crawlers/scheduleCrawler";
import scheduleDetailCrawler from "./crawlers/scheduleCrawler";

const schedule = require("node-schedule");
const { now } = require("mongoose");

var job = schedule.scheduleJob("10 44 19 * * *", async function () {
    let mNow = new Date();
    mNow.setDate(mNow.getDate()-7);
    console.log(mNow.toString());
    const accountUrls = await AccountUrl.find({});
    for (let i=0; i<accountUrls.length; i++){
        // ê³„ì • urlì„ í•˜ë‚˜ì”© ìˆœíšŒí•˜ì—¬ ê²Œì‹œë¬¼ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í•¨
        // í¬ìŠ¤íŠ¸ dbì—ì„œ ê³„ì • urlì„ ê¸°ì¤€ìœ¼ë¡œ ë½‘ìŒ
        await schedulePostCrawler(accountUrls[i]);
        const postUrls = await CrawlUrlPost.find({
            // uploadTime:{$gt : mNow}
        });
        console.log(postUrls);
        for (let j=0; j<postUrls.length; j++){
            await scheduleDetailCrawler(postUrls[j], accountUrls[i]);
        }
    }
});
const port = process.env.PORT || 80;

const handleListening = () =>
    console.log(`âœ… server listening from http://localhost:${port} ðŸš€`);
app.listen(port, handleListening);
  